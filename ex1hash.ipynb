{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import random as rnd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This bloom filter class will have two ins_functions. \n",
    "# The first will contain the array representing the bloom filter,\n",
    "# the second is a list of hash functions which witance attributes:\n",
    "# Bloom_Filter.array and Bloom_Filter.hashll be used to insert and search elements on the data structure.\n",
    "class Bloom_Filter:\n",
    "    \n",
    "    \n",
    "    def __init__(self, size, hash_functions):\n",
    "        self._array = np.empty(size, dtype = bool)\n",
    "        self._hash_functions = hash_functions\n",
    "    \n",
    "   \n",
    "    def insert(self, element):\n",
    "        for function in self._hash_functions:\n",
    "            self._array[function(element)] = True\n",
    "            \n",
    "    def check(self, element):\n",
    "        for function in self._hash_functions:\n",
    "            if(not self._array[function(element)]):\n",
    "                return(False)\n",
    "        return(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000000\n"
     ]
    }
   ],
   "source": [
    "# #We know the folllowing approximate formula to get a reasonable value of m given an error tolerance p as well as the size n of the elements we are going to insert on the set\n",
    "#     m = -\\frac{n \\ln{p}}{(\\ln{2})^{2}}\n",
    "\n",
    "# For the error tolerance $p$ we are going t choose the value $0.01$ so that we'll have only a 1\\% rate of false positives.\n",
    "passwords = open(\"passwords1.txt\", \"r\")\n",
    "\n",
    "counter = 0\n",
    "while(passwords.readline()):\n",
    "    counter = counter + 1\n",
    "passwords.close()\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have found out thar our list consists of 100 milions passwords. \n",
    "\n",
    "Knowing this we can finally compute m with the formula given above and get\n",
    "\n",
    "m =958505838\n",
    "\n",
    "k = \\frac{m}{n}\\ln{2}\n",
    "\n",
    "k = 6.64\n",
    "\n",
    "so we're going to use seven hash functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 !\n",
      "122 z\n"
     ]
    }
   ],
   "source": [
    "# We're going to save the minimum as well the maximum possible character in our file\n",
    "#(characters are ordered by their ASCII code)\n",
    "\n",
    "passwords = open(\"passwords1.txt\", \"r\")\n",
    "\n",
    "\n",
    "minimum = 102\n",
    "maximum = 102\n",
    "\n",
    "\n",
    "for _ in range(1000000):\n",
    "    string = passwords.readline()\n",
    "    for character in string[:19]: \n",
    "        if(ord(character) < minimum):\n",
    "            minimum = ord(character)\n",
    "        if(ord(character) > maximum):\n",
    "            maximum = ord(character)\n",
    "\n",
    "print(minimum, chr(minimum))\n",
    "print(maximum, chr(maximum))\n",
    "passwords.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that every password can contain characters ranging from \"!\" to \"z\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "passwords = open(\"passwords1.txt\", \"r\")\n",
    "\n",
    "\n",
    "counter = [0] * (122 - 33 + 1)\n",
    "\n",
    "\n",
    "for _ in range(1000000):\n",
    "    string = passwords.readline()\n",
    "    for character in string[:19]:\n",
    "        counter[ord(character) - 33] += 1\n",
    "\n",
    "passwords.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[226536,\n",
       " 226375,\n",
       " 226357,\n",
       " 226105,\n",
       " 226044,\n",
       " 226000,\n",
       " 226268,\n",
       " 226404,\n",
       " 225767,\n",
       " 225890,\n",
       " 225885,\n",
       " 226388,\n",
       " 226831,\n",
       " 225541,\n",
       " 225986,\n",
       " 226636,\n",
       " 225616,\n",
       " 227077,\n",
       " 226304,\n",
       " 227385,\n",
       " 226377,\n",
       " 225768,\n",
       " 226336,\n",
       " 226474,\n",
       " 226330,\n",
       " 226024,\n",
       " 226416,\n",
       " 226617,\n",
       " 226811,\n",
       " 226216,\n",
       " 226053,\n",
       " 226097,\n",
       " 225798,\n",
       " 226659,\n",
       " 225852,\n",
       " 226279,\n",
       " 226296,\n",
       " 226135,\n",
       " 226755,\n",
       " 226109,\n",
       " 226002,\n",
       " 225869,\n",
       " 226628,\n",
       " 225940,\n",
       " 226091,\n",
       " 226075,\n",
       " 225593,\n",
       " 225928,\n",
       " 225867,\n",
       " 226701,\n",
       " 225958,\n",
       " 226349,\n",
       " 226193,\n",
       " 226762,\n",
       " 225935,\n",
       " 226347,\n",
       " 226287,\n",
       " 226075,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 226032,\n",
       " 225611,\n",
       " 226913,\n",
       " 226309,\n",
       " 225951,\n",
       " 226027,\n",
       " 225492,\n",
       " 226486,\n",
       " 225835,\n",
       " 225963,\n",
       " 226979,\n",
       " 226746,\n",
       " 225956,\n",
       " 226440,\n",
       " 226128,\n",
       " 225894,\n",
       " 225349,\n",
       " 225799,\n",
       " 226374,\n",
       " 226345,\n",
       " 225788,\n",
       " 225929,\n",
       " 225759,\n",
       " 225880,\n",
       " 226971,\n",
       " 225647]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "every password in the file is a randome string where every character is independently drawn in the set of characters whose ASCII code ranges from 33 to 122, excluding those one whose code ranges from 91 to 96."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_10(character):\n",
    "    value = ord(character)\n",
    "    \n",
    "    \n",
    "    if(value < 91):\n",
    "        return(value - 33)\n",
    "    else:\n",
    "        return(value - 39)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We remember that values ranging from 91 to 96 do not appear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_1(string):\n",
    "    value  = 0\n",
    "    for index in range(len(string) - 1, -1, -1):\n",
    "        value = (84 * value + get_base_10(string[index])) % 958505838\n",
    "    return(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_string(string, step):\n",
    "    return(string[step:] + string[:step])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our other six functions and since they will be all similar we're going to define an high order function which will take as parameters one hash function (in our case hash_1) and a number $k$ and will return our $k$-th hash function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_function(first_hash_function, k):\n",
    "    \n",
    "   \n",
    "    return(lambda x : hash_1(rotate_string(x, k - 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we're going to inizialize our Bloom_Filter class save our hash functions in a list after that we can pass it as a parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_functions = [hash_function(hash_1, index + 1) for index in range(7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function returns the number of strings from the second data set that are possibly contained in the first data set\n",
    "# and the execution time for finding this number\n",
    "def task(first_data_set, second_data_set, m, hash_functions):\n",
    "    \n",
    "   \n",
    "    bloom_filter = Bloom_Filter(m, hash_functions)\n",
    "    \n",
    "    \n",
    "    strings = open(first_data_set, \"r\")\n",
    "    start = time.time()\n",
    "    while(True):\n",
    "        string = strings.readline()\n",
    "        if(string == \"\"):\n",
    "            break\n",
    "        string = string[:len(string) - 1] \n",
    "        bloom_filter.insert(string)\n",
    "    strings.close()\n",
    "    \n",
    "# This can check how many strings from the second data set are probably on the first data set  \n",
    "# Possible duplicates containing list also created\n",
    "    strings = open(second_data_set, \"r\")\n",
    "    possible_dups = []\n",
    "    while(True):\n",
    "        string = strings.readline()\n",
    "        if(string == \"\"):\n",
    "            break\n",
    "        string = string[:len(string) - 1]\n",
    "        if(bloom_filter.check(string)):\n",
    "            possible_dups.append(string)\n",
    "    end = time.time()\n",
    "    strings.close()\n",
    "    \n",
    "    return((possible_dups, end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hash functions used:  7\n",
      "Number of possibly duplicates:  14261334\n",
      "Probability of false positives: 0.01\n",
      "Execution time:  6857.633438587189\n"
     ]
    }
   ],
   "source": [
    "if(not os.path.isfile(\"possible_dups.txt\")):\n",
    "    result = task(\"passwords1.txt\", \"passwords2.txt\", 958505838, hash_functions)\n",
    "    f = open(\"possible_dups.txt\", \"w\")\n",
    "    f.write(str(result[1]) + \"\\n\")\n",
    "    for password in result[0]:\n",
    "        f.write(password + \"\\n\")\n",
    "    f.close()\n",
    "else:\n",
    "    f = open(\"possible_dups.txt\", \"r\")\n",
    "    result = [[], 0]\n",
    "    result[1] = float(f.readline())\n",
    "    while(True):\n",
    "        string = f.readline()\n",
    "        if(string == \"\"):\n",
    "            break\n",
    "        string = string[:len(string) - 1]\n",
    "        result[0].append(string)\n",
    "    f.close()\n",
    "\n",
    "# We print the results\n",
    "print('Number of hash functions used: ', len(hash_functions))\n",
    "print('Number of possibly duplicates: ', len(result[0]))\n",
    "print('Probability of false positives: 0.01')\n",
    "print('Execution time: ', result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BONUS\n",
    "\n",
    "Assuming that our hash function behaves well (and we hope so based on our discussions in the previous sections) all this process should take an amount of time linear in the size n =100000000 of the first data set, which seems reasonable.\n",
    "\n",
    "So let's start by creating our array hash_duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_dictionary(list_of_data, hash_function):\n",
    "    to_return = defaultdict(list)\n",
    "    for element in list_of_data:\n",
    "        to_return[hash_function(element)].append(element)\n",
    "    return(to_return)\n",
    "#We now create our dictionary of possibly duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_dups_dict = hash_dictionary(result[0], hash_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of false positives: 261334\n"
     ]
    }
   ],
   "source": [
    "f = open(\"passwords1.txt\", \"r\")\n",
    "\n",
    "while(True):\n",
    "    string = f.readline()\n",
    "    if(string == \"\"):\n",
    "        break\n",
    "    string = string[:len(string) - 1]\n",
    "    hash_value = hash_1(string)\n",
    "    if(string in possible_dups_dict[hash_value]):\n",
    "        possible_dups_dict[hash_value].remove(string)\n",
    "\n",
    "f.close()\n",
    "\n",
    "false_positives = []\n",
    "for elements in possible_dups_dict.values():\n",
    "    false_positives.extend(elements)\n",
    "\n",
    "print(\"Number of false positives: \" + str(len(false_positives)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the percentage of false positives is approximately 1.8%. This is a bit more than 1% as we initially asked, probably due to the fact that, as we have seen, our hash functions can't be exactly independent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
