{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import random as rnd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class is going to represent a bloom filter, so that we can organize all the implementation and methods\n",
    "# of the data structure in a single class.\n",
    "class Bloom_Filter:\n",
    "    \n",
    "    # To the constructor we're going to pass the size of the array representing the bloom filter\n",
    "    # and the list of hash functions that will be used for our methods\n",
    "    def _init_(self, size, hash_functions):\n",
    "        self._array = np.empty(size, dtype = bool)\n",
    "        self._hash_functions = hash_functions\n",
    "    \n",
    "    # This function is for adding elements to the bloom filter\n",
    "    def insert(self, element):\n",
    "        for function in self._hash_functions:\n",
    "            self._array[function(element)] = True\n",
    "            \n",
    "    # This function is for checking if an element is possibly on the bloom filter or definitely not in it.\n",
    "    # It returns True if the element is possibly on it, False if it's definetely not on it.\n",
    "    def check(self, element):\n",
    "        for function in self._hash_functions:\n",
    "            if(not self._array[function(element)]):\n",
    "                return(False)\n",
    "        return(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000000\n"
     ]
    }
   ],
   "source": [
    "passwords = open(\"passwords1.txt\", \"r\")\n",
    "# It's worth noting that when Python opens a file it's not going to save it in memory\n",
    "# so we are not cheating on our task by just opening the file if we don't read it all at once\n",
    "\n",
    "counter = 0\n",
    "while(passwords.readline()):\n",
    "    counter = counter + 1\n",
    "passwords.close()\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 !\n",
      "122 z\n"
     ]
    }
   ],
   "source": [
    "passwords = open(\"passwords1.txt\", \"r\")\n",
    "\n",
    "# We're going to save the minimum as well the maximum possible character in our file (characters are ordered by their ASCII code)\n",
    "minimum = 102\n",
    "maximum = 102\n",
    "\n",
    "# We're going to look at only the first 1'000'000 entries of the file so to speed up the process\n",
    "# implicitly assuming that the underlying distribution is homogenous throughout the file\n",
    "for _ in range(1000000):\n",
    "    string = passwords.readline()\n",
    "    for character in string[:19]: # It's important we get rid of the last character, which is always a \"\\n\"\n",
    "        if(ord(character) < minimum):\n",
    "            minimum = ord(character)\n",
    "        if(ord(character) > maximum):\n",
    "            maximum = ord(character)\n",
    "\n",
    "print(minimum, chr(minimum))\n",
    "print(maximum, chr(maximum))\n",
    "passwords.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "passwords = open(\"passwords1.txt\", \"r\")\n",
    "\n",
    "# Here we're going to save how many times a character appears on the file, at position i will be the number of times\n",
    "# chr(i + 33) appeared\n",
    "counter = [0] * (122 - 33 + 1)\n",
    "\n",
    "# Again we're just looking at the first 1'000'000 to speed up the process\n",
    "for _ in range(1000000):\n",
    "    string = passwords.readline()\n",
    "    for character in string[:19]:\n",
    "        counter[ord(character) - 33] += 1\n",
    "\n",
    "passwords.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[226536,\n",
       " 226375,\n",
       " 226357,\n",
       " 226105,\n",
       " 226044,\n",
       " 226000,\n",
       " 226268,\n",
       " 226404,\n",
       " 225767,\n",
       " 225890,\n",
       " 225885,\n",
       " 226388,\n",
       " 226831,\n",
       " 225541,\n",
       " 225986,\n",
       " 226636,\n",
       " 225616,\n",
       " 227077,\n",
       " 226304,\n",
       " 227385,\n",
       " 226377,\n",
       " 225768,\n",
       " 226336,\n",
       " 226474,\n",
       " 226330,\n",
       " 226024,\n",
       " 226416,\n",
       " 226617,\n",
       " 226811,\n",
       " 226216,\n",
       " 226053,\n",
       " 226097,\n",
       " 225798,\n",
       " 226659,\n",
       " 225852,\n",
       " 226279,\n",
       " 226296,\n",
       " 226135,\n",
       " 226755,\n",
       " 226109,\n",
       " 226002,\n",
       " 225869,\n",
       " 226628,\n",
       " 225940,\n",
       " 226091,\n",
       " 226075,\n",
       " 225593,\n",
       " 225928,\n",
       " 225867,\n",
       " 226701,\n",
       " 225958,\n",
       " 226349,\n",
       " 226193,\n",
       " 226762,\n",
       " 225935,\n",
       " 226347,\n",
       " 226287,\n",
       " 226075,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 226032,\n",
       " 225611,\n",
       " 226913,\n",
       " 226309,\n",
       " 225951,\n",
       " 226027,\n",
       " 225492,\n",
       " 226486,\n",
       " 225835,\n",
       " 225963,\n",
       " 226979,\n",
       " 226746,\n",
       " 225956,\n",
       " 226440,\n",
       " 226128,\n",
       " 225894,\n",
       " 225349,\n",
       " 225799,\n",
       " 226374,\n",
       " 226345,\n",
       " 225788,\n",
       " 225929,\n",
       " 225759,\n",
       " 225880,\n",
       " 226971,\n",
       " 225647]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_10(character):\n",
    "    value = ord(character)\n",
    "    \n",
    "    # We remember that values ranging from 91 to 96 do not appear\n",
    "    if(value < 91):\n",
    "        return(value - 33)\n",
    "    else:\n",
    "        return(value - 39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_1(string):\n",
    "    value  = 0\n",
    "    for index in range(len(string) - 1, -1, -1):\n",
    "        value = (84 * value + get_base_10(string[index])) % 958505838\n",
    "    return(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_string(string, step):\n",
    "    return(string[step:] + string[:step])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_function(first_hash_function, k):\n",
    "    \n",
    "    # Our k-th hash function will just apply hash_1 to the string rotated by k steps\n",
    "    return(lambda x : hash_1(rotate_string(x, k - 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_functions = [hash_function(hash_1, index + 1) for index in range(7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function takes as parameters the name of the file containing the first data set, the name of the file \n",
    "# containing the second data set, the size m of the array used to represen the bloom filter and\n",
    "# the list of hash functions used by the bloom filter\n",
    "\n",
    "# The function returns the number of strings from the second data set that are possibly contained in the first data set\n",
    "# and the execution time for finding this number\n",
    "def task(first_data_set, second_data_set, m, hash_functions):\n",
    "    \n",
    "    # We initialize our bloom filter\n",
    "    bloom_filter = Bloom_Filter(m, hash_functions)\n",
    "    \n",
    "    # We add every string in the first data set to the bloom filter\n",
    "    strings = open(first_data_set, \"r\")\n",
    "    start = time.time()\n",
    "    while(True):\n",
    "        string = strings.readline()\n",
    "        if(string == \"\"):\n",
    "            break\n",
    "        string = string[:len(string) - 1] # We need to get rid of the \"\\n\" at the end\n",
    "        bloom_filter.insert(string)\n",
    "    strings.close()\n",
    "    \n",
    "    # We now check how many strings from the second data set are probably on the first data set\n",
    "    # and we also create a list containing this possibly duplicates\n",
    "    strings = open(second_data_set, \"r\")\n",
    "    possibly_duplicates = []\n",
    "    while(True):\n",
    "        string = strings.readline()\n",
    "        if(string == \"\"):\n",
    "            break\n",
    "        string = string[:len(string) - 1]\n",
    "        if(bloom_filter.check(string)):\n",
    "            possibly_duplicates.append(string)\n",
    "    end = time.time()\n",
    "    strings.close()\n",
    "    \n",
    "    return((possibly_duplicates, end - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Bloom_Filter() takes no arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-4adb24abb05a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"possibly_duplicates.txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"passwords1.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"passwords2.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m958505838\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhash_functions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"possibly_duplicates.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpassword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-baefd9a0d82e>\u001b[0m in \u001b[0;36mtask\u001b[1;34m(first_data_set, second_data_set, m, hash_functions)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# We initialize our bloom filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mbloom_filter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBloom_Filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhash_functions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# We add every string in the first data set to the bloom filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Bloom_Filter() takes no arguments"
     ]
    }
   ],
   "source": [
    "if(not os.path.isfile(\"possibly_duplicates.txt\")):\n",
    "    result = task(\"passwords1.txt\", \"passwords2.txt\", 958505838, hash_functions)\n",
    "    f = open(\"possibly_duplicates.txt\", \"w\")\n",
    "    f.write(str(result[1]) + \"\\n\")\n",
    "    for password in result[0]:\n",
    "        f.write(password + \"\\n\")\n",
    "    f.close()\n",
    "else:\n",
    "    f = open(\"possibly_duplicates.txt\", \"r\")\n",
    "    result = [[], 0]\n",
    "    result[1] = float(f.readline())\n",
    "    while(True):\n",
    "        string = f.readline()\n",
    "        if(string == \"\"):\n",
    "            break\n",
    "        string = string[:len(string) - 1]\n",
    "        result[0].append(string)\n",
    "    f.close()\n",
    "# We print the asked results\n",
    "print('Number of hash functions used: ', len(hash_functions))\n",
    "print('Number of possibly duplicates: ', len(result[0]))\n",
    "print('Probability of false positives: 0.01')\n",
    "print('Execution time: ', result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
